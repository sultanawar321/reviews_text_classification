{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQf1baks4GcZ"
      },
      "source": [
        "### This notebook includes:\n",
        "\n",
        "1) Fine-Tuning the SetFit Model:\n",
        "   - Fine-tune the SetFit (Sentence Transformers) Hugging Face model on a small labeled dataset of customer reviews to solve a multi-class classification problem and generate topics/themes for unlabeled data.\n",
        "\n",
        "2) Quick Fine-Tuning Demo:\n",
        "   - Demonstration of quick fine-tuning using sample data from the Datasets library.\n",
        "\n",
        "3) Model Inference:\n",
        "   - Perform inference on unseen review data points to predict categories.\n",
        "\n",
        "4) Baseline Evaluation Mechanism:\n",
        "   - Evaluate model predictions using Fuzzywuzzy and Regex for a baseline comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXsGvFf65fPB"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install transformers==4.40.2\n",
        "!pip install setfit==1.0.3\n",
        "!pip install fuzzywuzzy==0.18.0\n",
        "!pip install loguru==0.6.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8AVKinv4Gcb"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import re\n",
        "from datetime import date\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from fuzzywuzzy import fuzz\n",
        "from google.colab import files\n",
        "from loguru import logger\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Hugging Face and SetFit Imports\n",
        "from huggingface_hub import notebook_login\n",
        "from setfit import SetFitModel, Trainer, TrainingArguments\n",
        "from datasets import Dataset, load_dataset\n",
        "\n",
        "# Ignore warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4jvsWMa4Gcd"
      },
      "outputs": [],
      "source": [
        "# Set Main Variables\n",
        "SETFIT_TRAINING_MODEL = \"sentence-transformers/paraphrase-mpnet-base-v2\"\n",
        "TEST_SIZE = 0.15\n",
        "Training_Arguments = TrainingArguments(\n",
        "    batch_size=16,  # num samples are passed through the model at once before updating the model's parameters\n",
        "    num_epochs=1,  # num of complete passes through training data\n",
        "    seed=42,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IrWAugu4Gcd"
      },
      "source": [
        "### 1. Data Preparation for fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nSUJJT-xK0b"
      },
      "outputs": [],
      "source": [
        "def data_prep():\n",
        "    \"\"\"\n",
        "    Reads the raw data from a CSV file, preprocesses it,\n",
        "    and returns aa a DataFrame.\n",
        "    \"\"\"\n",
        "    # Prompt user to upload the reviews csv file\n",
        "    logger.info(\"Uploading the labeled reviews dataset from local machine\")\n",
        "    uploaded = files.upload()\n",
        "    # Read the csv file as pandas df\n",
        "    df_raw = pd.read_csv(\"labelled_reviews.csv\")\n",
        "    df_raw = df_raw[[\"text\", \"label\"]]\n",
        "    # Drop null values if any\n",
        "    df_raw = df_raw.dropna(subset=[\"text\", \"label\"])\n",
        "    df_raw[\"label\"] = df_raw[\"label\"].str.strip()\n",
        "    # Apply a numeric mapping for the categories\n",
        "    category_mapping = {\n",
        "        \"Flights and Departures\": 1,\n",
        "        \"Entertainment and Food\": 2,\n",
        "        \"Cabin Comfort and Baggage\": 3,\n",
        "        \"Lounge Experience\": 4,\n",
        "        \"Boarding and Crew Experience\": 5,\n",
        "        \"Bookings and Refunds\": 6,\n",
        "    }\n",
        "    df_raw[\"label\"] = df_raw[\"label\"].map(category_mapping)\n",
        "    # Re sample the data\n",
        "    df_raw = df_raw.sample(frac=1)\n",
        "    return df_raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDCzTIpHtqbX"
      },
      "outputs": [],
      "source": [
        "# Upload, load, and prepare the labeled reviews dataset\n",
        "df_training = data_prep()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix1R2Jx94Gce"
      },
      "source": [
        "### 2. Split Train/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGbREjJYzGpN"
      },
      "outputs": [],
      "source": [
        "def data_split_train_test(responses, test_size):\n",
        "    \"\"\"\n",
        "    This function splits the dataset into train and validation based on test size\n",
        "    \"\"\"\n",
        "    responses.dropna(subset=[\"label\"], inplace=True)\n",
        "    train, val = train_test_split(\n",
        "        responses,\n",
        "        test_size=test_size,\n",
        "        random_state=42,\n",
        "        shuffle=True,\n",
        "        stratify=responses[\"label\"],\n",
        "    )\n",
        "    train_pd, val_pd = map(\n",
        "        lambda x: x.reset_index(drop=True),\n",
        "        [\n",
        "            train,\n",
        "            val,\n",
        "        ],\n",
        "    )\n",
        "    return train_pd, val_pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUIOfYi_tqbX"
      },
      "outputs": [],
      "source": [
        "# Apply train_test split\n",
        "train_pd, val_pd = data_split_train_test(df_training, TEST_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AykJLGoi4Gce"
      },
      "source": [
        "### 3. Data Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cN4jCSX0xor"
      },
      "outputs": [],
      "source": [
        "def data_transformation(train_pd, val_pd):\n",
        "    \"\"\"\n",
        "    This function transforms the pandas to dataset, a format accepted by the transformers\n",
        "    \"\"\"\n",
        "    # transform from pandas into datasets format (accpeted by the transfomers)\n",
        "    train = Dataset.from_pandas(train_pd)\n",
        "    val = Dataset.from_pandas(val_pd)\n",
        "    return train, val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPGfcxaVtqbY"
      },
      "outputs": [],
      "source": [
        "# Transform data to datasets format\n",
        "train_data, val_data = data_transformation(train_pd, val_pd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voimf9Kg4Gcf"
      },
      "source": [
        "### 4. Apply Fine-tuning on small labeled customers reviews dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiHetSaK4Gcf"
      },
      "outputs": [],
      "source": [
        "def model_finetuning(MODEL, TrainingArguments, Train_Data, Val_Data):\n",
        "    \"\"\"\n",
        "    Fine-tunes the specified model on the provided training data and evaluates it on the validation data.\n",
        "    \"\"\"\n",
        "    # Initiate the model\n",
        "    model = SetFitModel.from_pretrained(MODEL)\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=TrainingArguments,\n",
        "        train_dataset=Train_Data,\n",
        "        eval_dataset=Val_Data,\n",
        "    )\n",
        "    logger.info(\"fine-tuning the Setfit model on dataset\")\n",
        "    # Start the finetuning job\n",
        "    trainer.train()\n",
        "    logger.info(\"saving the fine-tuned model\")\n",
        "    model_directory_timestamp = (\n",
        "        f'{date.today().strftime(\"%Y%m%d\")}-reviews-text-classification'\n",
        "    )\n",
        "    # Save the model locally\n",
        "    trainer.model.save_pretrained(model_directory_timestamp)\n",
        "    # Evaluate the model\n",
        "    metrics = trainer.evaluate()\n",
        "    logger.info(f\"Performance of the fine-tuned model: , {metrics}\")\n",
        "    return trainer, metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l01R5wvztqbY"
      },
      "outputs": [],
      "source": [
        "# Apply the model_fine_tuning function on the customers reviews train and val data\n",
        "# This needs GPU power to get completed due to data size\n",
        "trainer = model_finetuning(\n",
        "    SETFIT_TRAINING_MODEL, Training_Arguments, train_data, val_data\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVLUqPLaafJ7"
      },
      "source": [
        "### 5. Run a Fine-tuning demo on sample dataset from Datasets Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CGBr6WMYaK8"
      },
      "outputs": [],
      "source": [
        "def load_sample_training_dataset():\n",
        "    \"\"\"\n",
        "    Load a sample dataset from Datasets Library for fine-tuning demo\n",
        "    \"\"\"\n",
        "    # Load the dataset from datasets library\n",
        "    dataset = load_dataset(\"SetFit/SentEval-CR\")\n",
        "    # Select N examples per class (8 in this case) for the train dataset\n",
        "    train_ds = dataset[\"train\"].shuffle(seed=42).select(range(8 * 2))\n",
        "    # Get the test dataset\n",
        "    test_ds = dataset[\"test\"]\n",
        "    return train_ds, test_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41lHK3qHtqbY"
      },
      "outputs": [],
      "source": [
        "# Load the train and val datasets for a quick demo\n",
        "train_ds, val_ds = load_sample_training_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dq9eJRyYuoh"
      },
      "outputs": [],
      "source": [
        "# Apply the model fine-tuning function on the demo train and val datasets\n",
        "# This runs perfectly with CPU\n",
        "trainer_demo, metrics = model_finetuning(\n",
        "    SETFIT_TRAINING_MODEL, Training_Arguments, train_ds, val_ds\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TA_hagXtqbY"
      },
      "source": [
        "### 6. Push the fine-tuned model to hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSYIx74JtqbY"
      },
      "outputs": [],
      "source": [
        "# Execute this cell to paste the API access token generated from HuggingFace account and push the fine-tuned model to hub\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDv5btyVtqbY"
      },
      "outputs": [],
      "source": [
        "# Add the repo name followed by the assigned model name\n",
        "trainer_demo.push_to_hub(\"sultanaw/fine_tuned_setfit_pydata_demo\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brUzQvY1tqbY"
      },
      "source": [
        "### 7. Load the input data for inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJzmHynFtqbY"
      },
      "outputs": [],
      "source": [
        "def load_sample_inference_data():\n",
        "    \"\"\"\n",
        "    Uploads the data from local machine and randomly selects 3%\n",
        "    \"\"\"\n",
        "    logger.info(\n",
        "        \"Uploading the reviews csv file from local machine and sampling small data\"\n",
        "    )\n",
        "    uploaded = files.upload()\n",
        "    # Read the data as pandas df\n",
        "    data = pd.read_csv(\"reviews.csv\")\n",
        "    # Load sample reviews data\n",
        "    data = data[[\"ReviewBody\"]].sample(frac=0.03)\n",
        "    data[\"ReviewBody\"] = data[\"ReviewBody\"].astype(str)\n",
        "    # Select non-null values\n",
        "    data = data[data[\"ReviewBody\"].notnull()]\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOj1O7xutqbZ"
      },
      "outputs": [],
      "source": [
        "# Load the input reviews data for inference\n",
        "data = load_sample_inference_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkqB4ibTtqbZ"
      },
      "source": [
        "### 8. Generate inference using the fine-tuned SF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_Hgah-7tqbZ"
      },
      "outputs": [],
      "source": [
        "def generate_inference(data: pd.DataFrame):\n",
        "    \"\"\"\n",
        "    This functuons loads the fine-tuned customers reviews model from the online HF hub and runs inference on sample of reviews\n",
        "    \"\"\"\n",
        "    # Load the fine-tuned model from the hub\n",
        "    fine_tuned_model = SetFitModel.from_pretrained(\"sultanaw/customer_reviews_setfit\")\n",
        "    # Run inference on the customers reviews to generate lables/themes\n",
        "    labels = fine_tuned_model.predict(data[\"ReviewBody\"].tolist())\n",
        "    data[\"predicted_numeric_label\"] = labels\n",
        "    # Reverse the key-value pairs of the category mapping dictionary to map predicted_numeric_label back to strings (topic categories)\n",
        "    category_mapping = {\n",
        "        \"Flights and Departures\": 1,\n",
        "        \"Entertainment and Food\": 2,\n",
        "        \"Cabin Comfort and Baggage\": 3,\n",
        "        \"Lounge Experience\": 4,\n",
        "        \"Boarding and Crew Experience\": 5,\n",
        "        \"Bookings and Refunds\": 6,\n",
        "    }\n",
        "    reverse_category_mapping = {v: k for k, v in category_mapping.items()}\n",
        "    # Apply the reversed mapping dict to the 'predicted numeric label' column and get the theme category\n",
        "    data[\"theme_category\"] = data[\"predicted_numeric_label\"].map(\n",
        "        reverse_category_mapping\n",
        "    )\n",
        "    logger.info(\n",
        "        \"The completion of fine-tuned setfit model predictions with number of customer reviews: {}\".format(\n",
        "            len(data)\n",
        "        )\n",
        "    )\n",
        "    return fine_tuned_model, reverse_category_mapping, data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WYvbr_6tqbZ"
      },
      "outputs": [],
      "source": [
        "# Generate inference (predicted theme categories) for reviews using the loaded fine-tuned model from HF\n",
        "fine_tuned_model, reverse_category_mapping, df_predictions = generate_inference(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D07gNt66tqbZ"
      },
      "outputs": [],
      "source": [
        "# Run inference on sample of given reviews\n",
        "sample_reviews = [\n",
        "    \"Fantastic entertainment system with a wide variety of movies and shows. Made the flight enjoyable!\",\n",
        "    \"Quick and hassle-free refund process.\",\n",
        "    \"My baggage arrived damaged, and seats were uncomfortable\",\n",
        "    \"Booking was easy, but the flight was delayed. The airline handled it well with regular updates.\",\n",
        "    \"The lounge was spacious, clean, and had excellent food and drinks. Great pre-flight relaxation!\",\n",
        "    \"Efficient and organized boarding. Clear announcements and helpful staff. Smooth experience!\",\n",
        "]\n",
        "\n",
        "# Predict numeric labels using the fine_tuned_model\n",
        "labels = fine_tuned_model.predict(sample_reviews).tolist()\n",
        "\n",
        "# Map labels to their respective categories\n",
        "for review, label in zip(sample_reviews, labels):\n",
        "    category_name = reverse_category_mapping.get(label, \"Unknown Category\")\n",
        "    print(f\"Review: {review}\\nPredicted Label: {label} (Category: {category_name})\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2khsvd-tqbZ"
      },
      "source": [
        "### 9. Baseline evaluation mechanism using Fuzzywuzzy and Regex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLChg4ygtqbZ"
      },
      "outputs": [],
      "source": [
        "def assign_keywords(row, mapping_dict):\n",
        "    \"\"\"\n",
        "    Assign list of keywords to be present in the text based on the predicted theme from fine-tuned model\n",
        "    \"\"\"\n",
        "    theme_category = row[\"theme_category\"]\n",
        "    if theme_category in mapping_dict:\n",
        "        return mapping_dict[theme_category]\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgaX51wqtqbZ"
      },
      "outputs": [],
      "source": [
        "def keywords_search(labels, content):\n",
        "    \"\"\"\n",
        "    Search for keywords in the content (review text) based on the established predicted theme by the fine-tuned model\n",
        "    Returns:\n",
        "        True if any of the labels are present in the content, False otherwise.\n",
        "    \"\"\"\n",
        "    for label in labels:\n",
        "        pattern = re.compile(label, re.IGNORECASE)  # Case-insensitive exact search\n",
        "        match = pattern.search(content)\n",
        "        similarity = fuzz.ratio(label.lower(), content.lower())  # Similarity search\n",
        "        if (\n",
        "            match is not None or similarity > 40\n",
        "        ):  # Using 40 as a threshold for similarity\n",
        "            return True\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujuvCeaBtqbZ"
      },
      "outputs": [],
      "source": [
        "def model_preds_eval(final_df, topic_mapping_keywords):\n",
        "    \"\"\"\n",
        "    This function applies the evaluation excercise between the predicted themes by the model and\n",
        "    baseline themes which are generated from the keywords look up using regex and fuzzywuzzy\n",
        "    \"\"\"\n",
        "    # Apply the function to create the 'key_words' column, words to be present in the review\n",
        "    final_df[\"key_words\"] = final_df.apply(\n",
        "        assign_keywords, args=(topic_mapping_keywords,), axis=1\n",
        "    )\n",
        "    # Apply the keywords search function\n",
        "    final_df[\"comparison_result\"] = final_df.apply(\n",
        "        lambda row: keywords_search(row[\"key_words\"], row[\"ReviewBody\"]), axis=1\n",
        "    )\n",
        "    value_counts = final_df[\"comparison_result\"].value_counts(normalize=True).round(2)\n",
        "    # Log the value counts using logger.info()\n",
        "    logger.info(\n",
        "        f\"The comparison result between the finetuned model's predictions and established themes based on keywords look-up is:\\n{value_counts}\"\n",
        "    )\n",
        "    return final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtFxzNEftqbZ"
      },
      "outputs": [],
      "source": [
        "# Define list of relevant key words per topic group\n",
        "topic_mapping_keywords = {\n",
        "    \"Boarding and Crew Experience\": [\n",
        "        \"attendants\",\n",
        "        \"pleasant\",\n",
        "        \"crew\",\n",
        "        \"member\",\n",
        "        \"boarding\",\n",
        "    ],\n",
        "    \"Entertainment and Food\": [\n",
        "        \"media\",\n",
        "        \"wifi\",\n",
        "        \"screen\",\n",
        "        \"headphones\",\n",
        "        \"electronics\",\n",
        "        \"snacks\",\n",
        "        \"drinks\",\n",
        "        \"food\",\n",
        "        \"baverages\",\n",
        "        \"catering\",\n",
        "        \"served\",\n",
        "        \"refreshments\",\n",
        "    ],\n",
        "    \"Cabin Comfort and Baggage\": [\n",
        "        \"seats\",\n",
        "        \"legging\",\n",
        "        \"legroom\",\n",
        "        \"sleep\",\n",
        "        \"space\",\n",
        "        \"luggage\",\n",
        "        \"baggage\",\n",
        "        \"bags\",\n",
        "        \"suitcase\",\n",
        "    ],\n",
        "    \"Lounge Experience\": [\"lounge\", \"service\", \"offerings\", \"business\"],\n",
        "    \"Bookings and Refunds\": [\n",
        "        \"rebook\",\n",
        "        \"tickets\",\n",
        "        \"refunds\",\n",
        "        \"pound\",\n",
        "        \"claim\",\n",
        "        \"complaint\",\n",
        "        \"call centre\",\n",
        "        \"email\",\n",
        "        \"online\",\n",
        "        \"system\",\n",
        "        \"telephoney\",\n",
        "        \"points\",\n",
        "    ],\n",
        "    \"Flights and Departures\": [\n",
        "        \"takeoff\",\n",
        "        \"flights\",\n",
        "        \"disruptions\",\n",
        "        \"delay\",\n",
        "        \"time\",\n",
        "        \"cancellations\",\n",
        "        \"return\",\n",
        "        \"inbound\",\n",
        "        \"outbound\",\n",
        "        \"desk\",\n",
        "        \"terminal\",\n",
        "        \"staff\",\n",
        "        \"connection\",\n",
        "        \"hotel\",\n",
        "    ],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsiDuMfttqbZ"
      },
      "outputs": [],
      "source": [
        "# Apply the evaluation exercise to monitor model predictions and compare them with baseline themes using lookup words\n",
        "final_df = model_preds_eval(df_predictions, topic_mapping_keywords)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}